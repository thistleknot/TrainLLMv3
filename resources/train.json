{
    "shuffle": true,
    "sub_sample_ratio": 0.15,
    "sub_sample": false,
    "quantized": true,
    "group_size": 128,
    "eos_token": "</s>",
    "batch_size": 7,
    "block_size": 2048,
    "model": "/home/user/oobabooga_linux/text-generation-webui/models/open_llama_3b_v2/",
    "input_file": "./source/",
    "model_name": "open_llama_3b_v2",
    "warm_ratio": 0.1,
    "learning_rate": 3e-4,
    "weight_decay": 0.1,
    "adam_beta1": 0.9,
    "adam_beta2": 0.999,
    "adam_epsilon": 1e-8,
    "min_epochs": 0,
    "epochs": 3,
    "patience": 2,
    "gradient_accumulation_steps": 1,
    "seed": 42,
    "split_ratio": 0.85,
    "stride_ratio": 0.5,
    "num_eval_examples": 4,
    "load_in_4bit": true,
    "bnb_4bit_use_double_quant": true,
    "bnb_4bit_quant_type": "fp4",
    "bnb_4bit_compute_dtype": "torch.bfloat16",
    "lora_r": 64,
    "lora_alpha": 16,
    "lora_dropout": 0.15,
    "bias": "all",
    "lora_task_type": "CAUSAL_LM",
    "EPS": 1e-8,
    "weight_decay": 0.1,
    "max_grad_norm": 0.3,
    "optim": "paged_adamw_8bit",
    "fine_tune_sample_size": 250,
    "zo_eps": 1e-3,
    "lr_scheduler_type": "linear",
    "mlm_prob": 0.15
}
